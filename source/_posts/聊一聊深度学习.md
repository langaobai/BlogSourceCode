title: 聊一聊深度学习
tags:
  - 算法
  - 深度学习
  - 机器学习
categories:
  - 算法
  - 深度学习
  - 机器学习
date: 2018-12-26 15:17:00
---

### 原来的深度学习是什么样的？

自从阿尔法狗打败中国的柯洁以后,就到处谣传着人工智能取代人类；

当时我的表情是：*黑人-文号*；

之前我有了解过有关计算机和人类比拼的，那个时候，是“深蓝”与国际象棋大师卡斯帕罗夫的比拼，卡斯帕罗夫赢了；

当时专家的结论：如果想要计算机达到人类国际象棋世界冠军的水平，那么计算机要有每秒计算 10 亿个局面的能力。深蓝接近了这一目标，但还没有达到。

然后这个事还没完，又过了1年以后，改进版“更深的蓝”卷土重来，再次与卡斯帕罗夫大战。

> 卡斯欣然接受挑战，他在 1996 年曾说：我能够感受到来自棋桌对面一种新型的智慧。但那是怪异、低效和不稳定的。我相信自己还有几年的安稳日子。
>
> 我全力要做到的是避免给予电脑任何具体的可进行针对性计算的目标。
>
> 可以说，当时的卡斯无论从技术还是心理上都不惧怕电脑。或许我们可以说当时的电脑还谈不上高级的人工智能。更准确地说是，电脑是在进行大数据库运算。
>
> 但它，已足够强大！它背后的“人类智囊团”里包括了4名国际大师。
>
> 　　比赛仍以 6 局定胜负。最终，“更深的蓝”以 3.5：2.5 击败了卡斯帕罗夫，其中第六局仅 19 个回合就通过精妙的弃子将对手的局面砸得粉碎。
>
> 比赛结束的第二天，该软件公司的股票价格上扬 3.6 个百分点，为公司带来多达两亿美元的收益。

当时的算法应该是一种穷尽的办法，将棋子的所有可能落脚点都进行一遍计算，推导出来的结果，进行优化选择后得到的答案，说的更清楚点就是**穷举法**；

但是到了围棋阶段就没有办法这么用了，因为不够算了，太多了，第一步有361种选择，第二步有360种选择，以后的情况大致如此，我们就以361为界，那么变化数是$361!$，约为$10^{768}$,那得多大啊。

但是说到阿尔法狗真的有人那么聪明么，那肯定不是的，只是说人们换了一种算法罢了，但距离真正的人工智能，我想或许还有很长的一段路要走的；

### 那么深度学习是怎么发展起来的呢？[^南极熊3d打印网]

作为机器学习最重要的一个分支，深度学习近年来发展迅猛，在国内外都引起了广泛的关注。

然而深度学习的火热也不是一时兴起的，而是经历了一段漫长的发展史。接下来我们了解一下深度学习的发展历程。

#### 深度学习的起源阶段

1943年，心里学家麦卡洛克和数学逻辑学家皮兹发表论文《神经活动中内在思想的逻辑演算》，提出了MP模型。MP模型是模仿神经元的结构和工作原理，构成出的一个基于神经网络的数学模型，本质上是一种“模拟人类大脑”的神经元模型。MP模型作为人工神经网络的起源，开创了人工神经网络的新时代，也奠定了神经网络模型的基础。

1949年，加拿大著名心理学家唐纳德·赫布在《行为的组织》中提出了一种基于无监督学习的规则——海布学习规则(Hebb Rule)。海布规则模仿人类认知世界的过程建立一种“网络模型”，该网络模型针对训练集进行大量的训练并提取训练集的统计特征，然后按照样本的相似程度进行分类，把相互之间联系密切的样本分为一类，这样就把样本分成了若干类。海布学习规则与“条件反射”机理一致，为以后的神经网络学习算法奠定了基础，具有重大的历史意义。

20世纪50年代末，在MP模型和海布学习规则的研究基础上，美国科学家罗森布拉特发现了一种类似于人类学习过程的学习算法——感知机学习。并于1958年，正式提出了由两层神经元组成的神经网络，称之为“感知器”。感知器本质上是一种线性模型，可以对输入的训练集数据进行二分类，且能够在训练集中自动更新权值。感知器的提出吸引了大量科学家对人工神经网络研究的兴趣，对神经网络的发展具有里程碑式的意义。

但随着研究的深入，在1969年，“AI之父”马文·明斯基和LOGO语言的创始人西蒙·派珀特共同编写了一本书籍《感知器》，在书中他们证明了单层感知器无法解决线性不可分问题（例如：异或问题）。由于这个致命的缺陷以及没有及时推广感知器到多层神经网络中，在20世纪70年代，人工神经网络进入了第一个寒冬期，人们对神经网络的研究也停滞了将近20年。

####  深度学习的发展阶段

1982年，著名物理学家约翰·霍普菲尔德发明了Hopfield神经网络。Hopfield神经网络是一种结合存储系统和二元系统的循环神经网络。Hopfield网络也可以模拟人类的记忆，根据激活函数的选取不同，有连续型和离散型两种类型，分别用于优化计算和联想记忆。但由于容易陷入局部最小值的缺陷，该算法并未在当时引起很大的轰动。

直到1986年，深度学习之父杰弗里·辛顿提出了一种适用于多层感知器的反向传播算法——BP算法。BP算法在传统神经网络正向传播的基础上，增加了误差的反向传播过程。反向传播过程不断地调整神经元之间的权值和阈值，直到输出的误差达到减小到允许的范围之内，或达到预先设定的训练次数为止。BP算法完美的解决了非线性分类问题，让人工神经网络再次的引起了人们广泛的关注。

但是由于八十年代计算机的硬件水平有限，如：运算能力跟不上，这就导致当神经网络的规模增大时，再使用BP算法会出现“梯度消失”的问题。这使得BP算法的发展受到了很大的限制。再加上90年代中期，以SVM为代表的其它浅层机器学习算法被提出，并在分类、回归问题上均取得了很好的效果，其原理又明显不同于神经网络模型，所以人工神经网络的发展再次进入了瓶颈期。

#### 深度学习的爆发阶段

2006年，杰弗里·辛顿以及他的学生鲁斯兰·萨拉赫丁诺夫正式提出了深度学习的概念。他们在世界顶级学术期刊《科学》发表的一篇文章中详细的给出了“梯度消失”问题的解决方案——通过无监督的学习方法逐层训练算法，再使用有监督的反向传播算法进行调优。该深度学习方法的提出，立即在学术圈引起了巨大的反响，以斯坦福大学、多伦多大学为代表的众多世界知名高校纷纷投入巨大的人力、财力进行深度学习领域的相关研究。而后又在迅速蔓延到工业界中。

2012年，在著名的ImageNet图像识别大赛中，杰弗里·辛顿领导的小组采用深度学习模型AlexNet一举夺冠。AlexNet采用ReLU激活函数，从根本上解决了梯度消失问题，并采用GPU极大的提高了模型的运算速度。同年，由斯坦福大学著名的吴恩达教授和世界顶尖计算机专家Jeff Dean共同主导的深度神经网络——DNN技术在图像识别领域取得了惊人的成绩，在ImageNet评测中成功的把错误率从26％降低到了15％。深度学习算法在世界大赛的脱颖而出，也再一次吸引了学术界和工业界对于深度学习领域的关注。

随着深度学习技术的不断进步以及数据处理能力的不断提升，2014年，Facebook基于深度学习技术的DeepFace项目，在人脸识别方面的准确率已经能达到97%以上，跟人类识别的准确率几乎没有差别。这样的结果也再一次证明了深度学习算法在图像识别方面的一骑绝尘。

2016年，随着谷歌公司基于深度学习开发的AlphaGo以4:1的比分战胜了国际顶尖围棋高手李世石，深度学习的热度一时无两。后来，AlphaGo又接连和众多世界级围棋高手过招，均取得了完胜。这也证明了在围棋界，基于深度学习技术的机器人已经超越了人类。

2017年，基于强化学习算法的AlphaGo升级版AlphaGo Zero横空出世。其采用“从零开始”、“无师自通”的学习模式，以100:0的比分轻而易举打败了之前的AlphaGo。除了围棋，它还精通国际象棋等其它棋类游戏，可以说是真正的棋类“天才”。此外在这一年，深度学习的相关算法在医疗、金融、艺术、无人驾驶等多个领域均取得了显著的成果。所以，也有专家把2017年看作是深度学习甚至是人工智能发展最为突飞猛进的一年。

所以在深度学习的浪潮之下，不管是AI的相关从业者还是其他各行各业的工作者，都应该以开放、学习的心态关注深度学习、人工智能的热点动态。人工智能正在悄无声息的改变着我们的生活！

#### 发展历程简要概述

![三者的关系](\img\articlePicture\learningDevelopment.png)

### 未来的深度学习会是怎么样的呢？

这里我们做一些基础的预测，不期待能有啥突破性的认识，但愿能认清一些脉络；

因为中国的工业4.0的提出，未来可能是爆发的 智能家居，智能制造，智能工作，铺助学习

这些方向都是未来很看好的，当然从投入来看，目前这几块都有不小的投入；

之后会怎样…

未完待续吧，等以后想到的了什么再来说说看…

[南极熊3d打印网]: http://mini.eastday.com/mobile/180314030343551.html#	"梳理百年深度学习发展史"

[^南极熊3d打印网]: http://mini.eastday.com/mobile/180314030343551.html#

