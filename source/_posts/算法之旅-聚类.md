title: 算法之旅-聚类
author: LanGaoBai
author_id: defaultAuthorId
language: zh-CN
tags:
  - 算法
  - 聚类
categories:
  - 算法
date: 2018-09-04 10:13:00

---

## 简介[^聚类算法百度百科]

聚类分析又称群分析，它是研究（样品或指标）分类问题的一种统计分析方法，同时也是数据挖掘的一个重要算法。

聚类（Cluster）分析是由若干模式（Pattern）组成的，通常，模式是一个度量（Measurement）的向量，或者是多维空间中的一个点。

聚类分析以相似性为基础，在一个聚类中的模式之间比不在同一聚类中的模式之间具有更多的相似性。

## 算法起源

俗话说：“物以类聚，人以群分”，在自然科学和社会科学中，存在着大量的**分类问题**。

所谓类，通俗地说，就是指相似元素的集合。

聚类分析起源于分类学，在古老的分类学中，人们主要依靠经验和专业知识来实现分类，很少利用数学工具进行定量的分类。

随着人类科学技术的发展，**对分类的要求越来越高**，以致有时仅凭经验和专业知识难以确切地进行分类，于是人们逐渐地把数学工具引用到了分类学中，**形成了数值分类学**，之后又**将多元分析的技术引入到数值分类学形成了聚类分析**。

聚类分析内容非常丰富，有系统聚类法、有序样品聚类法、动态聚类法、模糊聚类法、图论聚类法、聚类预报法等。

## 算法用途

聚类的用途是很广泛的。

在商业上，聚类可以帮助市场分析人员从消费者数据库中区分出不同的消费群体来，并且概括出每一类消费者的消费模式或者说习惯。

它作为数据挖掘中的一个模块，可以作为一个单独的工具以发现数据库中分布的一些深层的信息，并且概括出每一类的特点，或者把注意力放在某一个特定的类上以作进一步的分析；

并且，聚类分析也可以作为数据挖掘算法中其他分析算法的一个预处理步骤。

聚类分析的算法可以分为**划分法**（Partitioning Methods）、**层次法**（Hierarchical Methods）、**基于密度的方法**（density-based methods）、**基于网格的方法**（grid-based methods）、**基于模型的方法**（Model-Based Methods）。

## 聚类要求

### 可伸缩性

许多聚类算法在小于 200 个数据对象的小数据集合上工作得很好；

但是，一个大规模数据库可能包含几百万个对象，在这样的大数据集合样本上进行聚类可能会导致有偏的结果。

我们需要具有高度可伸缩性的聚类算法。

**这里的理解应该是有弹性，聚类的分类的标准应该是弹性的区间，如果死死的固定区间，那么就会存在游离所聚之类的外面；**

### 不同属性

许多算法被设计用来聚类数值类型的数据。

但是，应用可能要求聚类其他类型的数据，如**二元类型**(binary)，**分类/标称类型**（categorical/nominal），**序数型**（ordinal）数据，或者这些数**据类型的混合**。

**聚类不能仅仅给定一个数值区间就可以了的，如上所述在真正的应用过程中，聚合的应该是多属性的数据，多条件的聚合；**

### 任意形状

**许多聚类算法基于欧几里得或者曼哈顿距离度量来决定聚类（常用聚类算法）。**基于这样的距离度量的算法趋向于发现具有相近尺度和密度的**球状簇**。但是，一个簇可能是任意形状的。**提出能发现任意形状簇的算法是很重要的。**

**应该说真正符合现实需求的聚类算法通常的是复杂的，而不是简单的球形结构，应该是任意形状，而又同时符合真正聚合需求的算法。**

### 领域最小化

许多聚类算法在聚类分析中要求用户输入一定的参数，例如希望产生的簇的数目。**聚类结果对于输入参数十分敏感。**

**参数通常很难确定，特别是对于包含高维对象的数据集来说。**这样不仅加重了用户的负担，也使得聚类的质量难以控制。

**没有真正的对于数据精分，对于聚类的模型没有真正设计到位，才产生了聚类质量难于控制，让用户过多的选择。**

### 处理“噪声”（干扰）

**绝大多数现实中的数据库都包含了孤立点，缺失，或者错误的数据**。一些聚类算法对于这样的数据敏感，可能导致低质量的聚类结果。

**需要考虑到这种噪点类型数据的量，以及对于聚类整个的模型有何干扰，才能真正避免这类型数据造成的影响。**

### 记录顺序

一些聚类算法对于输入数据的顺序是敏感的。

例如，同一个数据集合，当以不同的顺序交给同一个算法时，可能生成差别很大的聚类结果。开发对数据输入顺序不敏感的算法具有重要的意义。

**应当避开涉及到数据顺序的问题，聚类算法真正需要聚合的对象是什么来操作；**

### 高维度（high dimensionality）

一个数据库或者数据仓库可能包含若干维或者属性。

**许多聚类算法擅长处理低维的数据，可能只涉及两到三维。**

**人类的眼睛在最多三维的情况下能够很好地判断聚类的质量。**

**在高维空间中聚类数据对象是非常有挑战性的**，特别是考虑到这样的**数据可能分布非常稀疏**，**而且高度偏斜。**

**多条件的进行聚合，其实这里可以对比空间数据的聚合，会更好的理解他所说的这段话**

### 基于约束

现实世界的应用可能需要在各种约束条件下进行聚类。

假设你的工作是在一个城市中为给定数目的自动提款机选择安放位置，为了作出决定，你可以对住宅区进行聚类，同时考虑如城市的河流和公路网，每个地区的客户要求等情况。

**要找到既满足特定的约束，又具有良好聚类特性的数据分组是一项具有挑战性的任务。**

### 解释性-可用性

**用户希望聚类结果是可解释的，可理解的，和可用的**。

也就是说，**聚类可能需要和特定的语义解释和应用相联系。**

**应用目标如何影响聚类方法的选择也是一个重要的研究课题。**

---

记住这些约束，我们对聚类分析的学习将按如下的步骤进行。

首先，学习不同类型的数据，以及它们对聚类方法的影响。

接着，给出了一个聚类方法的一般分类。

然后我们详细地讨论了各种聚类方法，包括**划分方法**，**层次方法**，**基于密度的方法**，**基于网格的方法**，以及**基于模型**的方法。最后我们探讨在**高维空间中的聚类**和**孤立点分析（outlier analysis）**。

> 这里的聚类要求，几乎包含了所有的种类的聚类情况，实际的应用过程中，可能不会有那么多，但是如果所涉及到的要求越高，要求精度越高，那么达成上面所有要求也成为了基本要求；
>

## 算法分类

**很难对聚类方法提出一个简洁的分类，因为这些类别可能重叠，从而使得一种方法具有几类的特征**，尽管如此，对于各种不同的聚类方法提供一个相对有组织的描述依然是有用的，为聚类分析计算方法主要有如下几种：

### 划分法

划分法(partitioning methods)，给定一个有N个元组或者纪录的数据集，分裂法将构造K个分组，每一个分组就代表一个聚类，K<N。而且这K个分组满足下列条件：

（1） 每一个分组**至少包含一个数据**纪录；
（2）**每一个数据纪录属于且仅属于一个分组**（注意：**这个要求在某些模糊聚类算法中可以放宽**）；

对于给定的K，算法首先给出一个初始的分组方法，以后通过反复迭代的方法改变分组，使得每一次改进之后的分组方案都较前一次好。

而所谓好的标准就是：**同一分组中的记录越近越好，而不同分组中的纪录越远越好。大部分划分方法是基于距离的。**

给定要构建的分区数k，划分方法首先创建一个初始化划分。

然后，它采用一种迭代的重定位技术，通过把对象从一个组移动到另一个组来进行划分。

一个好的划分的一般准备是：同一个簇中的对象尽可能相互接近或相关，而不同的簇中的对象尽可能远离或不同。

还有许多评判划分质量的其他准则。传统的划分方法可以扩展到子空间聚类，而不是搜索整个数据空间。

当存在很多属性并且数据稀疏时，这是有用的。**为了达到全局最优，基于划分的聚类可能需要穷举所有可能的划分，计算量极大。**

实际上，大多数应用都采用了流行的启发式方法，如**k-均值和k-中心算法，渐近的提高聚类质量，逼近局部最优解。**

**这些启发式聚类方法很适合发现中小规模的数据库中小规模的数据库中的球状簇**。

为了发现具有复杂形状的簇和对超大型数据集进行聚类，需要进一步扩展基于划分的方法。[^数据挖掘概念与技术]

使用这个基本思想的算法有：**K-MEANS算法、K-MEDOIDS算法、CLARANS算法**；

### 层次法

层次法(hierarchical methods)，这种方法对给定的数据集进行层次似的分解，直到某种条件满足为止。具体又可分为“自底向上”和“自顶向下”两种方案。

例如，在“自底向上”方案中，初始时每一个数据纪录都组成一个单独的组，在接下来的迭代中，它把那些相互邻近的组合并成一个组，直到所有的记录组成一个分组或者某个条件满足为止。

层次聚类方法可以是基于距离的或基于密度或连通性的。层次聚类方法的一些扩展也考虑了子空间聚类。**层次方法的缺陷在于，一旦一个步骤（合并或分裂）完成，它就不能被撤销。**

这个严格规定是有用的，因为不用担心不同选择的组合数目，它将产生较小的计算开销。然而这种技术不能更正错误的决定。已经提出了一些提高层次聚类质量的方法。[^数据挖掘概念与技术] 

代表算法有：**BIRCH算法、CURE算法、CHAMELEON算法**等；

### 密度算法

基于密度的方法(density-based methods)，基于密度的方法与其它方法的一个根本区别是：它不是基于各种各样的距离的，而是基于密度的。

这样就**能克服基于距离的算法只能发现“类圆形”的聚类的缺点**。

这个方法的指导思想就是，**只要一个区域中的点的密度大过某个阈值，就把它加到与之相近的聚类中去。**

代表算法有：**DBSCAN算法、OPTICS算法、DENCLUE算法**等；

### 图论聚类法

图论聚类方法解决的第一步是建立与问题相适应的图，**图的节点对应于被分析数据的最小单元，图的边（或弧）对应于最小处理单元数据之间的相似性度量。**

因此，每一个最小处理单元数据之间都会有一个度量表达，这就确保了数据的局部特性比较易于处理。图论聚类法是以样本数据的局域连接特征作为聚类的主要信息源，因而其主要优点是易于处理局部数据的特性。

### 网格算法

基于网格的方法(grid-based methods)，这种方法首先将数据空间划分成为有限个单元（cell）的网格结构,所有的处理都是以单个的单元为对象的。

**这么处理的一个突出的优点就是处理速度很快，通常这是与目标数据库中记录的个数无关的，它只与把数据空间分为多少个单元有关。**

代表算法有：**STING算法、CLIQUE算法、WAVE-CLUSTER算法**；

### 模型算法

基于模型的方法(model-based methods)，基于模型的方法给每一个聚类假定一个模型，然后去寻找能够很好的满足这个模型的数据集。

这样一个模型可能是数据点在空间中的密度分布函数或者其它。

它的一个潜在的假定就是：**目标数据集是由一系列的概率分布所决定的**。

通常有两种尝试方向：**统计的方案和神经网络的方案**。

## 具体方法

### K-MEANS

k均值聚类是最著名的划分聚类算法，由于简洁和效率使得他成为所有聚类算法中最广泛使用的。

给定一个数据点集合和需要的聚类数目k，k由用户指定，k均值算法根据某个距离函数反复把数据分入k个聚类中。

k是算法计算出的超参数，表示类的数量；

$k-means$可以自动分配样本到不同的类，但是不能决定究竟要分几个类。

k必须是一个比训练集样本数小的正整数。有时，类的数量是由问题内容指定的。

例如，一个鞋厂有三种新款式，它想知道每种新款式都有哪些潜在客户，于是它调研客户，然后从数据里找出三类。

也有一些问题没有指定聚类的数量，最优的聚类数量是不确定的。后面我将会详细介绍一些方法来估计最优聚类数量。[^风雪夜归子]

$k-means$的参数是类的重心位置和其内部观测值的位置。

与广义线性模型和决策树类似，$k-means$参数的最优解也是以成本函数最小化为目标。

$k-means$成本函数公式如下：

$$
J = \sum_{i=1}^{k}\sum_{j \in c_k}(x^{(j)}-\mu_i)^2
$$

$μi$是第$k$个类的重心位置。

成本函数是各个类畸变程度(distortions)之和。

每个类的畸变程度等于该类重心与其内部成员位置距离的平方和。

若类内部的成员彼此间越紧凑则类的畸变程度越小，反之，若类内部的成员彼此间越分散则类的畸变程度越大。

求解成本函数最小化的参数就是一个重复配置每个类包含的观测值，并不断移动类重心的过程。

首先，类的重心是随机确定的位置。实际上，重心位置等于随机选择的观测值的位置。

每次迭代的时候，Kmeans会把观测值分配到离它们最近的类，然后把重心移动到该类全部成员位置的平均值那里。




#### 算法详解

先随机选取K个对象作为初始的聚类中心。

然后计算每个对象与各个种子聚类中心之间的距离，把每个对象分配给距离它最近的聚类中心。

聚类中心以及分配给它们的对象就代表一个聚类。

一旦全部对象都被分配了，每个聚类的聚类中心会根据聚类中现有的对象被重新计算。

这个过程将不断重复直到满足某个终止条件。终止条件可以是以下任何一个：

1)没有（或最小数目）对象被重新分配给不同的聚类。

2)没有（或最小数目）聚类中心再发生变化。

3)误差平方和局部最小。

#### 算法分析[^k-means]

$k-means$ 算法接受输入量 k ；

然后将n个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。

聚类相似度是利用各聚类中对象的均值所获得一个“中心对象”（引力中心）来进行计算的。

$k-means$ 算法的工作过程说明如下：

首先从n个数据对象任意选择 k 个对象作为初始聚类中心；

而对于所剩下其它对象，则根据它们与这些聚类中心的相似度（距离），分别将它们分配给与其最相似的（聚类中心所代表的）聚类；

然后再计算每个所获新聚类的聚类中心（该聚类中所有对象的均值）；

不断重复这一过程直到标准测度函数开始收敛为止。

一般都采用均方差作为标准测度函数. 

k个聚类具有以下特点：各聚类本身尽可能的紧凑，而各聚类之间尽可能的分开。

算法的时间复杂度上界为$O(n*k*t)$, 其中t是迭代次数。

$k-means$算法是一种基于样本间相似性度量的间接聚类方法，属于非监督学习方法。

此算法以k为参数，把n 个对象分为k个簇，以使簇内具有较高的相似度，而且簇间的相似度较低。

相似度的计算根据一个簇中对象的平均值（被看作簇的重心）来进行。

此算法首先随机选择k个对象，每个对象代表一个聚类的质心。

对于其余的每一个对象，根据该对象与各聚类质心之间的距离，把它分配到与之最相似的聚类中。然后，计算每个聚类的新质心。

重复上述过程，直到准则函数收敛。

$k-means$算法是一种较典型的逐点修改迭代的动态聚类算法，其要点是以误差平方和为准则函数。

逐点修改类中心：一个象元样本按某一原则，归属于某一组类后，就要重新计算这个组类的均值，并且以新的均值作为凝聚中心点进行下一次象元素聚类；

逐批修改类中心：在全部象元样本按某一组的类中心分类之后，再计算修改各类的均值，作为下一次分类的凝聚中心点。

#### 算法实现

```java


```





## 其他算法链接地址

[算法之旅-排序算法](http://blog.langaobai.top/2018/08/26/%E7%AE%97%E6%B3%95%E4%B9%8B%E6%97%85-%E6%8E%92%E5%BA%8F/)

[算法之旅-聚类算法](http://blog.langaobai.top/2018/09/04/%E7%AE%97%E6%B3%95%E4%B9%8B%E6%97%85-%E8%81%9A%E7%B1%BB/)

[算法之旅-列表搜索算法]()

[算法之旅-图表搜索算法]()

[算法之旅-数学类算法]()

[算法之旅-数据压缩算法]()

[算法之旅-安全算法]()

[算法之旅-数据结构]()

[^聚类算法百度百科]: https://baike.baidu.com/item/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95

[^数据挖掘概念与技术]: Jiawei Han．数据挖掘概念与技术：机械工业出版社，2012
[^风雪夜归子]: https://blog.csdn.net/u013719780/article/details/78413770
[^k-means]: https://baike.baidu.com/item/K-MEANS%E7%AE%97%E6%B3%95#1_2